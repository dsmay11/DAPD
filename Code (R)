---
title: "DAPD Final Code"
author: "David May"
date: "October 13, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(stats)
library(readxl)
```



```{r velocity}
Velocity<- read_excel("C:/Users/dsmay/Box/LAB DRIVE/LAB/Current Studies/DAPD - Dental Appliance for PD/GaitRite/DAPD- GaitRite Final Processed Versions/DAPD Gaitrite Master Data.xlsx", sheet= "Velocity")

Velocity$velocity <- (Velocity$velocity/100)

#This removes participant 406. Participant 406 should be removed as outlier.
Velocity <- Velocity[-c(5, 25, 45, 65), ]

#Create dataframes
Velocity_PRE_FWD <- Velocity[Velocity$condition=="PRE_FWD", ]
Velocity_POST_FWD <- Velocity[Velocity$condition== "POST_FWD", ]

#Define as factor
Velocity$condition <- factor(Velocity$condition)
Velocity$ID <- factor(Velocity$ID)

#Check for normality
shapiro.test(Velocity_PRE_FWD$velocity)
shapiro.test(Velocity_POST_FWD$velocity)

#t-test
t.test(x= Velocity_PRE_FWD$velocity, y= Velocity_POST_FWD$velocity, paired= TRUE)

#Cohen's d
2.4316/(sqrt(19))

#mean and SD
mean(Velocity_PRE_FWD$velocity)
mean(Velocity_POST_FWD$velocity)
sd(Velocity_PRE_FWD$velocity)
sd(Velocity_POST_FWD$velocity)

```



```{r cadence, echo=FALSE}
Cadence<- read_excel("C:/Users/dsmay/Box/LAB DRIVE/LAB/Current Studies/DAPD - Dental Appliance for PD/GaitRite/DAPD- GaitRite Final Processed Versions/DAPD Gaitrite Master Data.xlsx", sheet= "Cadence")

#Define as factor
Cadence$condition <- factor(Cadence$condition)
Cadence$ID <- factor(Cadence$ID)

#Remove the outlier (participant 406).
Cadence <- Cadence[-c(5, 25, 45, 65), ]

#Create dataframes
Cadence_PRE_FWD <- Cadence[Cadence$condition=="PRE_FWD", ]
Cadence_POST_FWD <- Cadence[Cadence$condition== "POST_FWD", ]

#Check for normality
shapiro.test(Cadence_PRE_FWD$cadence)
shapiro.test(Cadence_POST_FWD$cadence)

#Run t-test
t.test(x= Cadence_PRE_FWD$cadence, y= Cadence_POST_FWD$cadence, paired= TRUE)
mean(Cadence_PRE_FWD$cadence)
sd(Cadence_PRE_FWD$cadence)
mean(Cadence_POST_FWD$cadence)
sd(Cadence_POST_FWD$cadence)

#cohen's d
2.6942/(sqrt(19))
```

```{r stride length, echo=FALSE}
#Import L stride length data
LSR<- read_excel("C:/Users/dsmay/Box/LAB DRIVE/LAB/Current Studies/DAPD - Dental Appliance for PD/GaitRite/DAPD- GaitRite Final Processed Versions/DAPD Gaitrite Master Data.xlsx", sheet= "L_stride_length_cm")

LSR$condition <- factor(LSR$condition)
LSR$ID <- factor(LSR$ID)

#Import R stride length data
RSR<- read_excel("C:/Users/dsmay/Box/LAB DRIVE/LAB/Current Studies/DAPD - Dental Appliance for PD/GaitRite/DAPD- GaitRite Final Processed Versions/DAPD Gaitrite Master Data.xlsx", sheet= "R_stride_length_cm")

RSR$condition <- factor(RSR$condition)
RSR$ID <- factor(RSR$ID)

#Make an average stride length column (averaging L and R)
RSR$mean <- ((RSR$R_stride_length_cm + LSR$L_stride_length_cm)/2)

#Modify data frames
RSR_PRE_FWD <- RSR[1:20, ]
RSR_POST_FWD <- RSR[41:60, ]

#Run t-test
t.test(x= RSR_PRE_FWD$mean, y= RSR_POST_FWD$mean, paired= TRUE)
mean(RSR_PRE_FWD$mean)
sd(RSR_PRE_FWD$mean)
mean(RSR_POST_FWD$mean)
sd(RSR_POST_FWD$mean)

#Cohen's d
2.492/(sqrt(20))
```

```{r follow up gaitrite data, echo=FALSE}
fu.data <- read_excel("C:/Users/dsmay/Box/Oral Splint Pilot/Follow-up gaitrite data processed.xlsx")

#Check for normality
shapiro.test(fu.data$PRE.Velocity)
shapiro.test(fu.data$FU.Velocity)
shapiro.test(fu.data$PRE.Cadence)
shapiro.test(fu.data$FU.Cadence)
shapiro.test(fu.data$PRE.Stride.Length.Avg)
shapiro.test(fu.data$FU.Stride.Length.Avg)

#Convert units of velocity to m/s
fu.data$PRE.Velocity <- (fu.data$PRE.Velocity/100)
fu.data$FU.Velocity <- (fu.data$FU.Velocity/100)

t.test(x= fu.data$PRE.Velocity, y= fu.data$FU.Velocity, paired=TRUE)
t.test(x= fu.data$PRE.Cadence, y= fu.data$FU.Cadence, paired=TRUE)
wilcox.test(x= fu.data$PRE.Stride.Length.Avg, y= fu.data$FU.Stride.Length.Avg, paired=TRUE, conf.int=TRUE)

#Velocity
mean(fu.data$PRE.Velocity)
sd(fu.data$PRE.Velocity)
mean(fu.data$FU.Velocity)
sd(fu.data$FU.Velocity)
1.3192/(sqrt(8))

#Cadence
mean(fu.data$PRE.Cadence)
sd(fu.data$PRE.Cadence)
mean(fu.data$FU.Cadence)
sd(fu.data$FU.Cadence)
1.4667/(sqrt(8))

#Stride Length
mean(fu.data$PRE.Stride.Length.Avg)
sd(fu.data$PRE.Stride.Length.Avg)
mean(fu.data$FU.Stride.Length.Avg)
sd(fu.data$FU.Stride.Length.Avg)
1.2325/(sqrt(8))

#Use t.test function to calculate mean difference and 95% CI
t.test(x= fu.data$PRE.Stride.Length.Avg, y= fu.data$FU.Stride.Length.Avg, paired=TRUE)

```

```{r motor setup, include=FALSE}
#Import motor data (grip strength, etc.)
#Pre and post data only.
MasterData <- read.csv("C:/Users/dsmay/Box/LAB DRIVE/LAB/Current Studies/DAPD - Dental Appliance for PD/DAPD David Abstract February Data.csv")
PreData <- MasterData[MasterData$Event.Name== "Pre-Device Baseline", ]
PostData <- MasterData[MasterData$Event.Name== "Post-Device Baseline", ]

#Here is where I've come back in later and added the follow-up data (n=8)
MasterDataFU <- read.csv("C:/Users/dsmay/Box/Oral Splint Pilot/handwriting grip followup data.csv")
PreDataFU <- MasterDataFU[MasterDataFU$Event.Name== "Pre-Device Baseline", ]
FU.DataFU <- MasterDataFU[MasterDataFU$Event.Name== "Follow-Up", ]
```

# **Grip Strength: Dominant Hand**
```{r grip strength dom hand, echo= FALSE}
#First, calculate everything for pre to post
#Mean/SD: Pre
mean(PreData$Average.for.Dominant.Hand..kg.)
sd(PreData$Average.for.Dominant.Hand..kg.)

#Mean/SD: Post
mean(PostData$Average.for.Dominant.Hand..kg.)
sd(PostData$Average.for.Dominant.Hand..kg.)

shapiro.test(PreData$Average.for.Dominant.Hand..kg.)
shapiro.test(PostData$Average.for.Dominant.Hand..kg.)

t.test(x= PreData$Average.for.Dominant.Hand..kg., y= PostData$Average.for.Dominant.Hand..kg., paired= TRUE)

-0.33956/(sqrt(20))

#Now, calculate everything for pre to FU
mean(PreDataFU$Average.for.Dominant.Hand..kg.)
sd(PreDataFU$Average.for.Dominant.Hand..kg.)

mean(FU.DataFU$Average.for.Dominant.Hand..kg.)
sd(FU.DataFU$Average.for.Dominant.Hand..kg.)

#Check for normality (normal enough)
shapiro.test(PreDataFU$Average.for.Dominant.Hand..kg.)
shapiro.test(FU.DataFU$Average.for.Dominant.Hand..kg.)

t.test(x= PreDataFU$Average.for.Dominant.Hand..kg., y= FU.DataFU$Average.for.Dominant.Hand..kg., paired= TRUE)

1.3009/(sqrt(8))
```


# **Grip Strength: Non-Dominant Hand**
```{r grip strength non dom hand, echo= FALSE}
mean(PreData$Average.for.Non.Dominant.Hand..kg.)
sd(PreData$Average.for.Non.Dominant.Hand..kg.)
mean(PostData$Average.for.Non.Dominant.Hand..kg.)
sd(PostData$Average.for.Non.Dominant.Hand..kg.)

shapiro.test(PreData$Average.for.Non.Dominant.Hand..kg.)
shapiro.test(PostData$Average.for.Non.Dominant.Hand..kg.)

t.test(x= PreData$Average.for.Non.Dominant.Hand..kg., y= PostData$Average.for.Non.Dominant.Hand..kg., paired= TRUE)

0.73784/(sqrt(20))

#Now, calculate everything for pre to FU
mean(PreDataFU$Average.for.Non.Dominant.Hand..kg.)
sd(PreDataFU$Average.for.Non.Dominant.Hand..kg.)

mean(FU.DataFU$Average.for.Non.Dominant.Hand..kg.)
sd(FU.DataFU$Average.for.Non.Dominant.Hand..kg.)

#Check for normality (normal enough)
shapiro.test(PreDataFU$Average.for.Non.Dominant.Hand..kg.)
shapiro.test(FU.DataFU$Average.for.Non.Dominant.Hand..kg.)

t.test(x= PreDataFU$Average.for.Non.Dominant.Hand..kg., y= FU.DataFU$Average.for.Non.Dominant.Hand..kg., paired= TRUE)

#Effect size (Cohen's d)
3.2567/(sqrt(8))

```


# **Handwriting: Average Sentence Length**
```{r average sentence length, echo= FALSE}
mean(PreData$Average.Sentence.Length..cm.)
sd(PreData$Average.Sentence.Length..cm)
mean(PostData$Average.Sentence.Length..cm.)
sd(PostData$Average.Sentence.Length..cm.)

shapiro.test(PreData$Average.Sentence.Length..cm.)
shapiro.test(PostData$Average.Sentence.Length..cm.)

t.test(x= PreData$Average.Sentence.Length..cm., y= PostData$Average.Sentence.Length..cm., paired= TRUE)

1.0697/(sqrt(20))



#Now, calculate everything for pre to FU
mean(PreDataFU$Average.Sentence.Length..cm.)
sd(PreDataFU$Average.Sentence.Length..cm.)

mean(FU.DataFU$Average.Sentence.Length..cm.)
sd(FU.DataFU$Average.Sentence.Length..cm.)

#Check for normality (normal enough)
shapiro.test(PreDataFU$Average.Sentence.Length..cm.)
shapiro.test(FU.DataFU$Average.Sentence.Length..cm.)

t.test(x= PreDataFU$Average.Sentence.Length..cm., y= FU.DataFU$Average.Sentence.Length..cm., paired= TRUE)

#Effect size (Cohen's d)
0.96048/(sqrt(8))


```


# **Handwriting: Average Height**
```{r average height, echo= FALSE}
mean(PreData$Average.Height..cm.)
sd(PreData$Average.Height..cm)
mean(PostData$Average.Height..cm.)
sd(PreData$Average.Height..cm)

shapiro.test(PreData$Average.Height..cm.)
shapiro.test(PostData$Average.Height..cm.)

t.test(x= PreData$Average.Height..cm., y= PostData$Average.Height..cm., paired= TRUE)

1.9604/(sqrt(20))


#Now, calculate everything for pre to FU
mean(PreDataFU$Average.Height..cm.)
sd(PreDataFU$Average.Height..cm.)

mean(FU.DataFU$Average.Height..cm.)
sd(FU.DataFU$Average.Height..cm.)

#Check for normality (normal enough)
shapiro.test(PreDataFU$Average.Height..cm.)
shapiro.test(FU.DataFU$Average.Height..cm.)

t.test(x= PreDataFU$Average.Height..cm., y= FU.DataFU$Average.Height..cm., paired= TRUE)

#Effect size (Cohen's d)
3.8358/(sqrt(8))
```


# **Handwriting: 3D Index**
```{r 3d index, echo= FALSE}
mean(PreData$Average.3D.Index..cm.)
sd(PreData$Average.3D.Index..cm.)
mean(PostData$Average.3D.Index..cm.)
sd(PostData$Average.3D.Index..cm.)

shapiro.test(PreData$Average.3D.Index..cm.)
shapiro.test(PostData$Average.3D.Index..cm.)
#Post data is not normally distributed

boxplot(PreData$Average.3D.Index..cm.)
boxplot(PostData$Average.3D.Index..cm.)
#There's an outlier in the post-data.

t.test(x= PreData$Average.3D.Index..cm., y= PostData$Average.3D.Index..cm., paired= TRUE)

#Run wilcox test. Not normally distributed.
wilcox.test(x= PreData$Average.3D.Index..cm., y= PostData$Average.3D.Index..cm., paired= TRUE)

0.23433/(sqrt(20))



#Now, calculate everything for pre to FU
mean(PreDataFU$Average.3D.Index..cm.)
sd(PreDataFU$Average.3D.Index..cm.)

mean(FU.DataFU$Average.3D.Index..cm.)
sd(FU.DataFU$Average.3D.Index..cm.)

#Check for normality (normal enough)
shapiro.test(PreDataFU$Average.3D.Index..cm.)
shapiro.test(FU.DataFU$Average.3D.Index..cm.)

boxplot(PreDataFU$Average.3D.Index..cm.)
boxplot(FU.DataFU$Average.3D.Index..cm.)

t.test(x= PreDataFU$Average.3D.Index..cm., y= FU.DataFU$Average.3D.Index..cm., paired= TRUE)

#Effect size (Cohen's d)
1.8766/(sqrt(8))
```


# **Total Mini BESTest Score**
```{r Mini BESTest, echo= FALSE}
mean(PreData$Mini.BESTest.total.score)
sd(PreData$Mini.BESTest.total.score)
mean(PostData$Mini.BESTest.total.score)
sd(PostData$Mini.BESTest.total.score)

shapiro.test(PreData$Mini.BESTest.total.score)
shapiro.test(PostData$Mini.BESTest.total.score)

t.test(x= PreData$Mini.BESTest.total.score, y= PostData$Mini.BESTest.total.score, paired= TRUE)
```

# **Demographics**

```{r demographics, echo= FALSE}
mean(PreData$X1.What.is.your.age..years..)
sd(PreData$X1.What.is.your.age..years..)

PreData$X11.1 <- (2020-(PreData$X11.What.year.were.you.diagnosed.with.PD.))
mean(PreData$X11.1)
sd(PreData$X11.1)


MasterData %>% 
  group_by(X2.What.is.your.gender.) %>%
  summarise(length(X2.What.is.your.gender.))
  

LEDD.data <- read.csv("C:/Users/dsmay/Box/Oral Splint Pilot/LEDD Data.csv")
mean(LEDD.data$Total.LEDD, na.rm=TRUE)
sd(LEDD.data$Total.LEDD, na.rm= TRUE)

```


```{r multiple.comparison, echo= FALSE}
#Acute motor effects multiple comparisons correction
p.values.acute <- c(.74, .47, .30, .06, .96, .93, .76, .03, .01, .02)
p.adjust(p.values.acute, method="holm", n=10)


#Long-term motor effects multiple comparisons correction
p.values.month <- c(.23, .01, .37, .01, .10, .15, .61, .23, .19, .25)
p.adjust(p.values.month, method="holm", n=10)

```



```{r UPDRS}
#Load UPDRS/BESTest Data
Blind <- read.csv("C:/Users/dsmay/Box/Oral Splint Pilot/Blind UPDRS BESTest Data 2.csv")

#Create table
blind_updrs <- Blind$MDS.UPDRS.Part.III.Total.Score[Blind$Event.Name== "Pre-Device Baseline"]
blind_updrs <- as.data.frame(blind_updrs)
blind_updrs$pre <- blind_updrs$blind_updrs
blind_updrs$ID <- Blind$Participant.ID[Blind$Event.Name=="Pre-Device Baseline"]
blind_updrs$post <- Blind$MDS.UPDRS.Part.III.Total.Score[Blind$Event.Name== "Post-Device Baseline"]
blind_updrs$fu <- Blind$MDS.UPDRS.Part.III.Total.Score[Blind$Event.Name== "Follow-Up"]

shapiro.test(blind_updrs$pre)
shapiro.test(blind_updrs$post)
shapiro.test(blind_updrs$fu)

#Run T-test of pre and post
t.test(x= blind_updrs$pre, y= blind_updrs$post, paired= TRUE)
mean(blind_updrs$pre)
sd(blind_updrs$pre)
mean(blind_updrs$post)
sd(blind_updrs$post)

#Cohen's D
0.088443/(sqrt(20))

#Create table with only follow-up participants
blind_updrs_fu <- blind_updrs[complete.cases(blind_updrs), ]
#Make Long Form (commented out)
#blind_updrs_fu <- blind_updrs_fu[ , -c(1,3)]
#blind_updrs_fu <- blind_updrs_fu %>% gather(key="condition", value= "UPDRS_Score")
#blind_updrs_fu$ID <- c(404, 405, 409, 410, 416, 417, 418, 424, 404, 405, 409, 410, 416, 417, 418, 424, 404, 405, 409, 410, 416, 417, 418, 424 )

#Convert ID and condition to factor variables
#blind_updrs_fu$condition <- as.factor(blind_updrs_fu$condition)
#blind_updrs_fu$ID <- as.factor(blind_updrs_fu$ID)

#Higher scores on UPDRS indicate worse motor performance.

#People got worse after one month (not significant). 

#t-test from pre to fu
t.test(x= blind_updrs_fu$pre, y= blind_updrs_fu$fu, paired=TRUE)
mean(blind_updrs_fu$pre)
sd(blind_updrs_fu$pre)
mean(blind_updrs_fu$fu)
sd(blind_updrs_fu$fu)

diff.data.updrs <- (blind_updrs_fu$fu- blind_updrs_fu$pre)
diff.data.updrs <- as.data.frame(diff.data.updrs)
diff.data.updrs$total <- diff.data.updrs$diff.data.updrs
cohendtotal<- ((mean(blind_updrs_fu$fu)-mean(blind_updrs_fu$pre))/sd(diff.data.updrs$total))
cohendtotal

1.6019/(sqrt(8))
```



```{r minibest.blind, echo=FALSE}
#Create table
blind_best <- Blind$Mini.BESTest.total.score[Blind$Event.Name== "Pre-Device Baseline"]
blind_best <- as.data.frame(blind_best)
blind_best$pre <- blind_best$blind_best
blind_best$ID <- Blind$Participant.ID[Blind$Event.Name=="Pre-Device Baseline"]
blind_best$post <- Blind$Mini.BESTest.total.score[Blind$Event.Name== "Post-Device Baseline"]
blind_best$fu <- Blind$Mini.BESTest.total.score[Blind$Event.Name== "Follow-Up"]

shapiro.test(blind_best$pre)
shapiro.test(blind_best$post)
shapiro.test(blind_best$fu)

#summary(blind_best$post)

#Run T-test of pre and post
t.test(x= blind_best$pre, y= blind_best$post, paired= TRUE)
mean(blind_best$pre, na.rm=TRUE)
sd(blind_best$pre, na.rm= TRUE)
mean(blind_best$post, na.rm= TRUE)
sd(blind_best$post, na.rm= TRUE)

#Cohen's d (pre to post)
0.31347/(sqrt(20))

#Create table with only follow-up participants
blind_best_fu <- blind_best[complete.cases(blind_best), ]
shapiro.test(blind_best_fu$pre)
shapiro.test(blind_best_fu$fu)

mean(blind_best_fu$pre)
sd(blind_best_fu$pre)
mean(blind_best_fu$fu)
sd(blind_best_fu$fu)

#Run Wilcox Test. Normality violated for fu data.
wilcox.test(x=blind_best_fu$pre, y=blind_best_fu$fu, paired=TRUE)
t.test(x=blind_best_fu$pre, y=blind_best_fu$fu, paired=TRUE)

#Cohen's d (pre to fu)
0.23477/(sqrt(8))

```


```{r quality of life}
QOLData <- read.csv("file:///C:/Users/dsmay/Box/Oral Splint Pilot/NQOL and PDQ39 Data.csv")


qualitydata <- QOLData$Sum.of.NFOGQ.items[QOLData$Event.Name== "Pre-Device Baseline"]
qualitydata <- as.data.frame(qualitydata)
qualitydata$NFOGQ.PRE <- qualitydata$qualitydata

qualitydata$NFOGQ.POST <- QOLData$Sum.of.NFOGQ.items[QOLData$Event.Name== "Follow-Up"]
qualitydata$ID <- QOLData$Participant.ID[QOLData$Event.Name== "Pre-Device Baseline"]

#Insert this when needed to remove incomplete cases
qualitydata <- qualitydata[complete.cases(qualitydata$NFOGQ.POST), ]

#Insert this to take out the "0" responses for NFOGQ
qualitydata <- subset(qualitydata, (NFOGQ.PRE!=0)| (NFOGQ.POST!=0))

#T-test for FOG
t.test(x= qualitydata$NFOGQ.PRE, y= qualitydata$NFOGQ.POST, paired=TRUE)
mean(qualitydata$NFOGQ.PRE)
sd(qualitydata$NFOGQ.PRE)
mean(qualitydata$NFOGQ.POST)
sd(qualitydata$NFOGQ.POST)

#median and IQR
summary(qualitydata$NFOGQ.PRE)
summary(qualitydata$NFOGQ.POST)

#T-statistic used to calculate cohen's d for nFOG
0.54689/(sqrt(13))

#Check for normality
shapiro.test(qualitydata$NFOGQ.PRE)
shapiro.test(qualitydata$NFOGQ.POST)

#Do Wilcoxon test. Not normally distributed.
wilcox.test(x= qualitydata$NFOGQ.PRE, y= qualitydata$NFOGQ.POST, paired=TRUE)

```


```{r pdq39, echo=FALSE}
#Add PDQ39 Items
qualitydata$Mobility.Dimension.pre <- QOLData$Mobility.Dimension[QOLData$Event.Name== "Pre-Device Baseline"]
qualitydata$Mobility.Dimension.post <-QOLData$Mobility.Dimension[QOLData$Event.Name== "Follow-Up"]

qualitydata$ADL.Dimension.pre <- QOLData$ADL.Dimension[QOLData$Event.Name== "Pre-Device Baseline"]
qualitydata$ADL.Dimension.post <-QOLData$ADL.Dimension[QOLData$Event.Name== "Follow-Up"]

qualitydata$Emotional.Well.Being.Dimension.pre <- QOLData$Emotional.Well.Being.Dimension[QOLData$Event.Name== "Pre-Device Baseline"]
qualitydata$Emotional.Well.Being.Dimension.post <-QOLData$Emotional.Well.Being.Dimension[QOLData$Event.Name== "Follow-Up"]

qualitydata$Stigma.Dimension.pre <- QOLData$Stigma.Dimension[QOLData$Event.Name== "Pre-Device Baseline"]
qualitydata$Stigma.Dimension.post <-QOLData$Stigma.Dimension[QOLData$Event.Name== "Follow-Up"]

qualitydata$Social.Support.Dimension.pre <- QOLData$Social.Support.Dimension[QOLData$Event.Name== "Pre-Device Baseline"]
qualitydata$Social.Support.Dimension.post <-QOLData$Social.Support.Dimension[QOLData$Event.Name== "Follow-Up"]

qualitydata$Cognitive.Impairment.Dimension.pre <- QOLData$Cognitive.Impairment.Dimension[QOLData$Event.Name== "Pre-Device Baseline"]
qualitydata$Cognitive.Impairment.Dimension.post <-QOLData$Cognitive.Impairment.Dimension[QOLData$Event.Name== "Follow-Up"]

qualitydata$Communication.Dimension.pre <- QOLData$Communication.Dimension[QOLData$Event.Name== "Pre-Device Baseline"]
qualitydata$Communication.Dimension.post <-QOLData$Communication.Dimension[QOLData$Event.Name== "Follow-Up"]

qualitydata$Bodily.Discomfort.Dimension.pre <- QOLData$Bodily.Discomfort.Dimension[QOLData$Event.Name== "Pre-Device Baseline"]
qualitydata$Bodily.Discomfort.Dimension.post <-QOLData$Bodily.Discomfort.Dimension[QOLData$Event.Name== "Follow-Up"]


#Make a column for total PDQ39
qualitydata$pdqtotal.pre <- (qualitydata$Mobility.Dimension.pre + qualitydata$ADL.Dimension.pre + qualitydata$Emotional.Well.Being.Dimension.pre + qualitydata$Stigma.Dimension.pre + qualitydata$Social.Support.Dimension.pre + qualitydata$Cognitive.Impairment.Dimension.pre + qualitydata$Communication.Dimension.pre + qualitydata$Bodily.Discomfort.Dimension.pre)

qualitydata$pdqtotal.post <- (qualitydata$Mobility.Dimension.post + qualitydata$ADL.Dimension.post + qualitydata$Emotional.Well.Being.Dimension.post + qualitydata$Stigma.Dimension.post + qualitydata$Social.Support.Dimension.post + qualitydata$Cognitive.Impairment.Dimension.post + qualitydata$Communication.Dimension.post + qualitydata$Bodily.Discomfort.Dimension.post)


#Make total "percentage" scores (divide total scores by 8)
qualitydata$pdqtotal.pre.pct <- qualitydata$pdqtotal.pre/8
qualitydata$pdqtotal.post.pct <- qualitydata$pdqtotal.post/8

#Run T-test
qualitydata <- qualitydata[complete.cases(qualitydata$NFOGQ.POST), ]
t.test(x=qualitydata$pdqtotal.pre.pct, y=qualitydata$pdqtotal.post.pct, paired=TRUE)
mean(qualitydata$pdqtotal.pre.pct)
sd(qualitydata$pdqtotal.pre.pct)
mean(qualitydata$pdqtotal.post.pct, na.rm=TRUE)
sd(qualitydata$pdqtotal.post.pct, na.rm=TRUE)


mean1 <- c(149.58, 97.08, 166.67, 315.83, 163.33, 4.17, 109.17, 158.75, 101.25, 115.83, 232.08, 162.08, 113.75)
mean2 <- c(106.67, 98.33, 144.58, 342.08, 111.25, 0, 250.42, 161.25, 53.33, 61.67, 203.33, 137.08, 133.33)
mean(mean1)
sd(mean1)
mean(mean2)
sd(mean2)

#Overall PDQ is not significant 

#Check for normality. (They're normal enough)
shapiro.test(qualitydata$pdqtotal.pre.pct)
shapiro.test(qualitydata$pdqtotal.post.pct)

#Cohen's d
0.46179/(sqrt(13))


```

```{r means and sd, echo=FALSE}
#taking out the rows with NA for questionnaires so I can calculate means and SD's.
qualitydata2 <- qualitydata[c(3, 4, 6, 7, 8, 9, 11, 12, 15, 16, 17, 18, 20), ]
mean(qualitydata2$NFOGQ.PRE)
sd(qualitydata2$NFOGQ.PRE)
mean(qualitydata2$NFOGQ.POST)
sd(qualitydata2$NFOGQ.POST)


```


```{r PDSS, echo= FALSE}
Master <- read.csv("file:///C:/Users/dsmay/Box/Oral Splint Pilot/April 9 Update Data.csv")

PDSS_Avg <- Master$Event.Name
PDSS_Avg <- as.data.frame(PDSS_Avg)
PDSS_Avg$ParticipantID <- Master$Ã¯..Participant.ID
PDSS_Avg$PDSS1 <- ((Master$PDSS.1.RS + Master$PDSS.1.ON)/2)
PDSS_Avg$PDSS2 <- ((Master$PDSS.2.RS + Master$PDSS.2.ON)/2)
PDSS_Avg$PDSS3 <- ((Master$PDSS.3.RS + Master$PDSS.3.ON)/2)
PDSS_Avg$PDSS4 <- ((Master$PDSS.4.RS + Master$PDSS.4.ON)/2)
PDSS_Avg$PDSS5 <- ((Master$PDSS.5.RS + Master$PDSS.5.ON)/2)
PDSS_Avg$PDSS6 <- ((Master$PDSS.6.RS + Master$PDSS.6.ON)/2)
PDSS_Avg$PDSS7 <- ((Master$PDSS.7.RS + Master$PDSS.7.ON)/2)
PDSS_Avg$PDSS8 <- ((Master$PDSS.8.RS + Master$PDSS.8.ON)/2)
PDSS_Avg$PDSS9 <- ((Master$PDSS.9.RS + Master$PDSS.9.ON)/2)
PDSS_Avg$PDSS10 <- ((Master$PDSS.10.RS + Master$PDSS.10.ON)/2)
PDSS_Avg$PDSS11 <- ((Master$PDSS.11.RS + Master$PDSS.11.ON)/2)
PDSS_Avg$PDSS12 <- ((Master$PDSS.12.RS + Master$PDSS.12.ON)/2)
PDSS_Avg$PDSS13 <- ((Master$PDSS.13.RS + Master$PDSS.13.ON)/2)
PDSS_Avg$PDSS14 <- ((Master$PDSS.14.RS + Master$PDSS.14.ON)/2)
PDSS_Avg$PDSS15 <- ((Master$PDSS.15.RS + Master$PDSS.15.ON)/2)

#Participant 412 and 413 are missing responses. I'm removing those participants. 
PDSS_Avg <- PDSS_Avg[PDSS_Avg$ParticipantID!= "412", ]
PDSS_Avg <- PDSS_Avg[PDSS_Avg$ParticipantID!= "413", ]

#Now we need a total PDSS score for each participant
PDSS_Avg$Total <- (PDSS_Avg$PDSS1 + PDSS_Avg$PDSS2 + PDSS_Avg$PDSS3 + PDSS_Avg$PDSS4 + PDSS_Avg$PDSS5 + PDSS_Avg$PDSS6 + PDSS_Avg$PDSS7 + PDSS_Avg$PDSS8 + PDSS_Avg$PDSS9 + PDSS_Avg$PDSS10 + PDSS_Avg$PDSS11 + PDSS_Avg$PDSS12 + PDSS_Avg$PDSS13 + PDSS_Avg$PDSS14 + PDSS_Avg$PDSS15)


```


```{r PDSS.t.test, echo=FALSE}
#Make a new data frame with pre and post in different columns
PDSS.test <- PDSS_Avg$Total[PDSS_Avg$PDSS_Avg== "Pre-Device Baseline"]
PDSS.test <- as.data.frame(PDSS.test)
PDSS.test$Pre <- PDSS.test$PDSS.test
PDSS.test$Post <- PDSS_Avg$Total[PDSS_Avg$PDSS_Avg== "Follow-Up"]
PDSS.test$ID <- PDSS_Avg$ParticipantID[PDSS_Avg$PDSS_Avg== "Follow-Up"]

#Let's get the mean score for pre and post
mean(PDSS.test$Pre)
sd(PDSS.test$Pre)

mean(PDSS.test$Post)
sd(PDSS.test$Post)

#Now a paired T test to see if the difference is significant
t.test(x= PDSS.test$Pre, y= PDSS.test$Post, paired= TRUE)

#Check for normality (normal enough)
shapiro.test(PDSS.test$Pre)
shapiro.test(PDSS.test$Post)

#Calculate effect size
0.52163/(sqrt(11))

#Participants report slightly better sleep after mouthpiece. Not significant. Only calculated from 11 participants.  2 participants had missing data. 
```


```{r PSQI.1, echo=FALSE}
#For PSQI Scoring Instructions see here: https://www.sleep.pitt.edu/instruments/
PSQI.data <- Master$Event.Name
PSQI.data <- as.data.frame(PSQI.data)
PSQI.data$ParticipantID <- Master$Ã¯..Participant.ID
PSQI.data$PSQI4 <- Master$PSQI.4

#Now we need to convert Question 4 from raw hours slept into 0-3 scores.
#7 or more hours per night is a 0 score
#DURAT score
PSQI.data$PSQI4[PSQI.data$PSQI4 >= 7] <- 0
PSQI.data$PSQI4[PSQI.data$PSQI4 >= 6] <- 1
PSQI.data$PSQI4[PSQI.data$PSQI4 >= 5] <- 2
PSQI.data$DURAT <- PSQI.data$PSQI4

#Convert question 5 data in master data to character data
Master$PSQI..5a <- as.character(Master$PSQI..5a)
Master$PSQI.5b <- as.character(Master$PSQI.5b)
Master$PSQI.5c <- as.character(Master$PSQI.5c)
Master$PSQI.5d <- as.character(Master$PSQI.5d)
Master$PSQI.5e <- as.character(Master$PSQI.5e)
Master$PSQI.5f <- as.character(Master$PSQI.5f)
Master$PSQI.5g <- as.character(Master$PSQI.5g)
Master$PSQI.5h <- as.character(Master$PSQI.5h)
Master$PSQI.5i <- as.character(Master$PSQI.5i)
Master$PSQI.5j2 <- as.character(Master$PSQI.5j2)

#Create a subset for just question 5
Question5 = Master[, c('PSQI..5a', 'PSQI.5b', 'PSQI.5c', 'PSQI.5d', 'PSQI.5e', 'PSQI.5f', 'PSQI.5g', 'PSQI.5h', 'PSQI.5i', 'PSQI.5j2')]

#Convert answer choices to numbers for Question 5
Question5[Question5 == "Not during the past month"] <- "0"
Question5[Question5 == "Less than once a week"] <- "1"
Question5[Question5 == "Once or twice a week"] <- "2"
Question5[Question5 == "Three or more times a week"] <- "3"

#Convert to numeric
Question5$PSQI..5a <- as.numeric(Question5$PSQI..5a)
Question5$PSQI.5b <- as.numeric(Question5$PSQI.5b)
Question5$PSQI.5c <- as.numeric(Question5$PSQI.5c)
Question5$PSQI.5d <- as.numeric(Question5$PSQI.5d)
Question5$PSQI.5e <- as.numeric(Question5$PSQI.5e)
Question5$PSQI.5f <- as.numeric(Question5$PSQI.5f)
Question5$PSQI.5g <- as.numeric(Question5$PSQI.5g)
Question5$PSQI.5h <- as.numeric(Question5$PSQI.5h)
Question5$PSQI.5i <- as.numeric(Question5$PSQI.5i)
Question5$PSQI.5j2 <- as.numeric(Question5$PSQI.5j2)

#Convert NA to 0. Add participant ID and condition
Question5[is.na(Question5)] = 0
Question5$Total5 <- (Question5$PSQI..5a + Question5$PSQI.5b+ Question5$PSQI.5c + Question5$PSQI.5d + Question5$PSQI.5e + Question5$PSQI.5f + Question5$PSQI.5g + Question5$PSQI.5h + Question5$PSQI.5i + Question5$PSQI.5j2)
Question5$ID <- Master$Ã¯..Participant.ID
Question5$condition <- Master$Event.Name

#Create another column with DISTB score
Question5$DISTB <- Question5$Total5

#Convert this column to appropriate score based on sheet
Question5$DISTB[Question5$DISTB == 0] <- 0
Question5$DISTB[Question5$DISTB > 0 & Question5$DISTB <= 9] <- 1
Question5$DISTB[Question5$DISTB > 9 & Question5$DISTB <= 18] <- 2
Question5$DISTB[Question5$DISTB > 18] <- 3

#Add this score to our PSQI data frame
PSQI.data$DISTB <- Question5$DISTB

```


```{r PSQI.2, echo=FALSE}
#Next we need to calculate LATEN, DAYDYS, HSE, SLPQUAL, and MEDS scores to get total PSQI
#LATEN
Question2= Master$PSQI.2
Question2 <- as.data.frame(Question2)
Question2$Question2 <- as.numeric(Question2$Question2)
Question2$LATEN<- Question2$Question2

Question2$LATEN[Question2$LATEN >= 0 & Question2$LATEN <= 15] <- 0
Question2$LATEN[Question2$LATEN > 15 & Question2$LATEN <= 30] <- 1
Question2$LATEN[Question2$LATEN > 30 & Question2$LATEN <= 60] <- 2
Question2$LATEN[Question2$LATEN > 60] <- 3
PSQI.data$LATEN <- Question2$LATEN

```

```{r PSQI.3, echo=FALSE}
#Next we need to calculate LATEN, DAYDYS, HSE, SLPQUAL, and MEDS scores to get total PSQI
#DAYDS
#Create subset and convert to character data
Question8and9 = Master[, c('PSQI.8', 'PSQI.9')]
Question8and9$PSQI.8 <- as.character(Question8and9$PSQI.8)
Question8and9$PSQI.9 <- as.character(Question8and9$PSQI.9)

#Convert answer choices to numeric
Question8and9$PSQI.8[Question8and9$PSQI.8 == "Not during the past month"] <- "0"
Question8and9$PSQI.8[Question8and9$PSQI.8 == "Less than once a week"] <- "1"
Question8and9$PSQI.8[Question8and9$PSQI.8 == "Once or twice a week"] <- "2"
Question8and9$PSQI.8[Question8and9$PSQI.8 == "Three or more times a week"] <- "3"

Question8and9$PSQI.9[Question8and9$PSQI.9 == "No problem at all"] <- "0"
Question8and9$PSQI.9[Question8and9$PSQI.9 == "Only a very slight problem"] <- "1"
Question8and9$PSQI.9[Question8and9$PSQI.9 == "Somewhat of a problem"] <- "2"
Question8and9$PSQI.9[Question8and9$PSQI.9 == "A very big problem"] <- "3"

#Add answer choice 8 and 9
Question8and9$PSQI.8 <- as.numeric(Question8and9$PSQI.8)
Question8and9$PSQI.9 <- as.numeric(Question8and9$PSQI.9)
Question8and9$totalraw <- (Question8and9$PSQI.8 + Question8and9$PSQI.9)
Question8and9$total <- Question8and9$totalraw

#Convert total to DAYDS score
Question8and9$total[Question8and9$total == 0] <- 0
Question8and9$total[Question8and9$total >= 1 & Question8and9$total <= 2] <- 1
Question8and9$total[Question8and9$total >= 3 & Question8and9$total <= 4] <- 2
Question8and9$total[Question8and9$total >= 5 & Question8and9$total <= 6] <- 3
Question8and9$DAYDS<- Question8and9$total

#add to PSQI data
PSQI.data$DAYDS <- Question8and9$DAYDS

```

```{r PSQI.4, echo=FALSE}
#Next we need to calculate LATEN, DAYDYS, HSE, SLPQUAL, and MEDS scores to get total PSQI
#HSE (basically looking at how much of the time spent in bed is actually spent sleeping)
Question1and3 <- c(6.33, 6.25, 7.5, 7.5, 9, 9.5, 7.5, 8, 6.75, 7.5, 8, 9, 9, 7.5, 10, 10, 7, 7.5, 9, 9, 8.5, 9, 8, 9, 10, 7.5)
Question1and3 <- as.data.frame(Question1and3)
Question1and3$ID <- Master$Ã¯..Participant.ID
Question1and3$tmphse <- ((Master$PSQI.4/Question1and3$Question1and3)*100)
Question1and3$total <- Question1and3$tmphse

#Recode as Form indicates
Question1and3$total[Question1and3$total < 65] <- 3
Question1and3$total[Question1and3$total >= 85] <- 0
Question1and3$total[Question1and3$total < 85 & Question1and3$total >= 75] <- 1
Question1and3$total[Question1and3$total < 75 & Question1and3$total >= 65] <- 2
PSQI.data$HSE <- Question1and3$total

```

```{r PSQI.5, echo=FALSE}
#SLPQUAL
Question6 <- as.data.frame(Master$PSQI.6)
Question6$Question6 <- Question6$`Master$PSQI.6`
Question6$Question6 <- as.character(Question6$Question6)

Question6$Question6[Question6$Question6 == "Very good"] <- "0"
Question6$Question6[Question6$Question6 == "Fairly good"] <- "1"
Question6$Question6[Question6$Question6 == "Fairly bad"] <- "2"
Question6$Question6[Question6$Question6 == "Very bad"] <- "3"

PSQI.data$SLPQUAL <- Question6$Question6

```

```{r PSQI.6, echo=FALSE}
#MEDS
Question7 <- as.data.frame(Master$PSQI.7)
Question7$Question7 <- Question7$`Master$PSQI.7`
Question7$Question7 <- as.character(Question7$Question7)

Question7$Question7[Question7$Question7 == "Not during the past month"] <- "0"
Question7$Question7[Question7$Question7 == "Less than once a week"] <- "1"
Question7$Question7[Question7$Question7 == "Once or twice a week"] <- "2"
Question7$Question7[Question7$Question7 == "Three or more times a week"] <- "3"

PSQI.data$MEDS <- as.numeric(Question7$Question7)
```

```{r PSQI.7, echo=FALSE}
#TOTAL
PSQI.data$DURAT <- as.numeric(PSQI.data$DURAT)
PSQI.data$DISTB <- as.numeric(PSQI.data$DISTB)
PSQI.data$LATEN <- as.numeric(PSQI.data$LATEN)
PSQI.data$DAYDS <- as.numeric(PSQI.data$DAYDS)
PSQI.data$HSE <- as.numeric(PSQI.data$HSE)
PSQI.data$SLPQUAL <- as.numeric(PSQI.data$SLPQUAL)


PSQI.data$TOTAL <- (PSQI.data$DURAT + PSQI.data$DISTB + PSQI.data$LATEN + PSQI.data$DAYDS + PSQI.data$HSE + PSQI.data$SLPQUAL + PSQI.data$MEDS)
```

```{r PSQI.8, echo=FALSE}
#We need to run a T-test on the change in total scores.
PSQI.test <- PSQI.data[PSQI.data$PSQI.data == "Pre-Device Baseline",]
PSQI.test2 <- PSQI.data[PSQI.data$PSQI.data == "Follow-Up", ]

mean(PSQI.test$TOTAL)
sd(PSQI.test$TOTAL)

mean(PSQI.test2$TOTAL)
sd(PSQI.test2$TOTAL)

t.test(x= PSQI.test$TOTAL, y= PSQI.test2$TOTAL, paired= TRUE)

#Check for normality. 
shapiro.test(PSQI.test$TOTAL)
shapiro.test(PSQI.test2$TOTAL)

#boxplot(PSQI.test$TOTAL)
#boxplot(PSQI.test2$TOTAL)

#Effect Size (Cohen's D)
0.11744/(sqrt(13))


```
